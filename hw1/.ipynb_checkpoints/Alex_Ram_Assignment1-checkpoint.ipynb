{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 \n",
    "#### CS395: Deep learning\n",
    "#### 2/26/18\n",
    "#### By Alex Ram\n",
    "\n",
    "### The code bellow is used for all three parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from keras.applications.resnet50 import ResNet50 \n",
    "from keras.preprocessing.image import img_to_array\n",
    "from IPython.display import Image\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code bellow was inspired by this tutorial: https://www.pyimagesearch.com/2017/12/11/image-classification-with-keras-and-deep-learning/\n",
    "#This will take the images and covert it to an array, also the labels\n",
    "#path to the pictures\n",
    "PATH = \"../../png/\"\n",
    "trainData = []\n",
    "trainLabels = []\n",
    "\n",
    "testData = []\n",
    "testLabels = []\n",
    " \n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = open(PATH + \"filelist.txt\").readlines()\n",
    "\n",
    "def convertImageToArray(imagePath):\n",
    "    image = cv2.imread(PATH + imagePath.strip())\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "for i in range(len(imagePaths)):\n",
    "    if i % 80 < 60:\n",
    "        #image coverted to array and appended to data set\n",
    "        trainData.append(convertImageToArray(imagePaths[i]))\n",
    "        \n",
    "        #labels of images appended to labels dataset\n",
    "        trainLabels.append(imagePaths[i].split(\"/\"))\n",
    "        trainLabels[-1][1] = trainLabels[-1][1].strip()\n",
    "    else:\n",
    "        testData.append(convertImageToArray(imagePaths[i]))\n",
    "        \n",
    "        testLabels.append(imagePaths[i].split(\"/\"))\n",
    "        testLabels[-1][1] = testLabels[-1][1].strip()\n",
    "        \n",
    "#covert label lists to numpy arrays to use later\n",
    "trainLabels = np.array(trainLabels)\n",
    "testLabels = np.array(testLabels)\n",
    "#get a set of just each type of lable\n",
    "uniqueLabels = set(trainLabels[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:\n",
    "### Using a pretrained network on imageNet to classify the sketches data set by training a classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model found here: https://keras.io/applications/#resnet50\n",
    "model = ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFeatures = []\n",
    "testFeatures = []\n",
    "\n",
    "#feature extraction from the image arrays using the resnet50 model\n",
    "for i in range(len(trainData)):\n",
    "    trainFeatures.append(model.predict(trainData[i]))\n",
    "    \n",
    "for i in range(len(testData)):\n",
    "    testFeatures.append(model.predict(testData[i]))\n",
    "\n",
    "#squeeze 'em\n",
    "trainFeatures = np.squeeze(trainFeatures)\n",
    "testFeatures = np.squeeze(testFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "15000/15000 [==============================] - 7s 450us/step - loss: 3.3138 - acc: 0.3342 - val_loss: 2.7167 - val_acc: 0.4456\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 6s 423us/step - loss: 2.3616 - acc: 0.5188 - val_loss: 2.7004 - val_acc: 0.4782\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 6s 415us/step - loss: 2.1370 - acc: 0.5711 - val_loss: 2.7349 - val_acc: 0.5066\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 6s 422us/step - loss: 2.0377 - acc: 0.6013 - val_loss: 2.7582 - val_acc: 0.5192\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 6s 404us/step - loss: 1.9444 - acc: 0.6286 - val_loss: 2.7976 - val_acc: 0.5404\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 7s 449us/step - loss: 1.8715 - acc: 0.6456 - val_loss: 2.8239 - val_acc: 0.5354\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 6s 422us/step - loss: 1.8245 - acc: 0.6581 - val_loss: 2.8867 - val_acc: 0.5446\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 6s 404us/step - loss: 1.7673 - acc: 0.6673 - val_loss: 2.8765 - val_acc: 0.5488\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 7s 442us/step - loss: 1.7409 - acc: 0.6823 - val_loss: 2.9171 - val_acc: 0.5492\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 6s 428us/step - loss: 1.6834 - acc: 0.6942 - val_loss: 2.8731 - val_acc: 0.5620\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 6s 421us/step - loss: 1.6519 - acc: 0.7044 - val_loss: 2.9704 - val_acc: 0.5592\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 6s 429us/step - loss: 1.6232 - acc: 0.7081 - val_loss: 2.9492 - val_acc: 0.5638\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 6s 413us/step - loss: 1.5899 - acc: 0.7195 - val_loss: 3.0003 - val_acc: 0.5614\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 6s 433us/step - loss: 1.5608 - acc: 0.7261 - val_loss: 3.0513 - val_acc: 0.5594\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 7s 437us/step - loss: 1.5374 - acc: 0.7295 - val_loss: 3.0364 - val_acc: 0.5676\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 6s 417us/step - loss: 1.5185 - acc: 0.7386 - val_loss: 3.0810 - val_acc: 0.5662\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 7s 438us/step - loss: 1.4958 - acc: 0.7415 - val_loss: 3.0816 - val_acc: 0.5700\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 6s 423us/step - loss: 1.4738 - acc: 0.7499 - val_loss: 3.1391 - val_acc: 0.5660\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 7s 443us/step - loss: 1.4575 - acc: 0.7499 - val_loss: 3.1593 - val_acc: 0.5740\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 7s 435us/step - loss: 1.4456 - acc: 0.7585 - val_loss: 3.2031 - val_acc: 0.5726\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 6s 421us/step - loss: 1.4204 - acc: 0.7635 - val_loss: 3.1953 - val_acc: 0.5718\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 7s 442us/step - loss: 1.4136 - acc: 0.7665 - val_loss: 3.2267 - val_acc: 0.5744\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 6s 432us/step - loss: 1.3788 - acc: 0.7675 - val_loss: 3.2502 - val_acc: 0.5660\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 6s 405us/step - loss: 1.3714 - acc: 0.7743 - val_loss: 3.2700 - val_acc: 0.5754\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 6s 420us/step - loss: 1.3486 - acc: 0.7747 - val_loss: 3.2791 - val_acc: 0.5708\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 6s 409us/step - loss: 1.3422 - acc: 0.7788 - val_loss: 3.3005 - val_acc: 0.5672\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 6s 427us/step - loss: 1.3286 - acc: 0.7827 - val_loss: 3.3155 - val_acc: 0.5726\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 6s 414us/step - loss: 1.3172 - acc: 0.7866 - val_loss: 3.3012 - val_acc: 0.5774\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 6s 430us/step - loss: 1.3070 - acc: 0.7865 - val_loss: 3.3461 - val_acc: 0.5804\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 6s 422us/step - loss: 1.2849 - acc: 0.7913 - val_loss: 3.4091 - val_acc: 0.5660\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 6s 400us/step - loss: 1.2838 - acc: 0.7937 - val_loss: 3.3973 - val_acc: 0.5724\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 6s 426us/step - loss: 1.2712 - acc: 0.7957 - val_loss: 3.3967 - val_acc: 0.5736\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 6s 409us/step - loss: 1.2624 - acc: 0.7990 - val_loss: 3.3948 - val_acc: 0.5720\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 6s 418us/step - loss: 1.2628 - acc: 0.8004 - val_loss: 3.4094 - val_acc: 0.5766\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 6s 432us/step - loss: 1.2409 - acc: 0.8075 - val_loss: 3.4361 - val_acc: 0.5732\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 6s 410us/step - loss: 1.2324 - acc: 0.8033 - val_loss: 3.4245 - val_acc: 0.5856\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 7s 436us/step - loss: 1.2142 - acc: 0.8066 - val_loss: 3.4976 - val_acc: 0.5790\n",
      "Epoch 38/50\n",
      "15000/15000 [==============================] - 6s 408us/step - loss: 1.2161 - acc: 0.8101 - val_loss: 3.4921 - val_acc: 0.5760\n",
      "Epoch 39/50\n",
      "15000/15000 [==============================] - 6s 412us/step - loss: 1.1971 - acc: 0.8144 - val_loss: 3.4642 - val_acc: 0.5832\n",
      "Epoch 40/50\n",
      "15000/15000 [==============================] - 6s 422us/step - loss: 1.1928 - acc: 0.8137 - val_loss: 3.4732 - val_acc: 0.5814\n",
      "Epoch 41/50\n",
      "15000/15000 [==============================] - 6s 406us/step - loss: 1.1730 - acc: 0.8169 - val_loss: 3.5628 - val_acc: 0.5772\n",
      "Epoch 42/50\n",
      "15000/15000 [==============================] - 6s 427us/step - loss: 1.1775 - acc: 0.8186 - val_loss: 3.4919 - val_acc: 0.5782\n",
      "Epoch 43/50\n",
      "15000/15000 [==============================] - 6s 412us/step - loss: 1.1762 - acc: 0.8203 - val_loss: 3.5390 - val_acc: 0.5762\n",
      "Epoch 44/50\n",
      "15000/15000 [==============================] - 6s 402us/step - loss: 1.1617 - acc: 0.8200 - val_loss: 3.5836 - val_acc: 0.5712\n",
      "Epoch 45/50\n",
      "15000/15000 [==============================] - 6s 415us/step - loss: 1.1559 - acc: 0.8230 - val_loss: 3.6140 - val_acc: 0.5760\n",
      "Epoch 46/50\n",
      "15000/15000 [==============================] - 6s 410us/step - loss: 1.1425 - acc: 0.8265 - val_loss: 3.5638 - val_acc: 0.5812\n",
      "Epoch 47/50\n",
      "15000/15000 [==============================] - 6s 421us/step - loss: 1.1387 - acc: 0.8265 - val_loss: 3.5604 - val_acc: 0.5830\n",
      "Epoch 48/50\n",
      "15000/15000 [==============================] - 6s 426us/step - loss: 1.1321 - acc: 0.8309 - val_loss: 3.6345 - val_acc: 0.5756\n",
      "Epoch 49/50\n",
      "15000/15000 [==============================] - 6s 402us/step - loss: 1.1302 - acc: 0.8302 - val_loss: 3.6423 - val_acc: 0.5770\n",
      "Epoch 50/50\n",
      "15000/15000 [==============================] - 6s 423us/step - loss: 1.1247 - acc: 0.8305 - val_loss: 3.6567 - val_acc: 0.5800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47ed4efeb8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code bellow inspired by https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "\n",
    "#Creates the classifier\n",
    "def createClassifier():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(250, input_dim=2048, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# encode class values as integers\n",
    "def convertToDummy(labels):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(labels[:,0])\n",
    "    encoded_Y = encoder.transform(labels[:,0])\n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "    return dummy_y\n",
    "\n",
    "trainDummyLabels = convertToDummy(trainLabels)\n",
    "testDummyLabels = convertToDummy(testLabels)\n",
    "\n",
    "estimator = createClassifier()\n",
    "estimator.fit(trainFeatures, trainDummyLabels, validation_data=(testFeatures, testDummyLabels), epochs=50, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### For all parts bellow I found out after running the code that I could have used the call back method in keras to show the best validation accuracy after all epochs. But for this run it looks like ~58%. Compared to 70-80% being te best performace, that's pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:\n",
    "### Allowing the entire pretrained network to be trained on the sketches data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I'm taking the resnet50 model defined in the previous part and adjustiong to have the classifier added to it.\n",
    "#This will allow the entire network to be trained in one go\n",
    "#code inspired by https://keras.io/applications/#resnet50\n",
    "\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(250, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "modelWithClassifier = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 4.6903 - acc: 0.0667 - val_loss: 9.9801 - val_acc: 0.0098\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 2.9415 - acc: 0.2991 - val_loss: 4.3576 - val_acc: 0.1468\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 2.0532 - acc: 0.4795 - val_loss: 2.7733 - val_acc: 0.3808\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 1.5415 - acc: 0.5877 - val_loss: 2.4009 - val_acc: 0.4666\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 1.1677 - acc: 0.6771 - val_loss: 1.8604 - val_acc: 0.5408\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.8591 - acc: 0.7500 - val_loss: 2.6971 - val_acc: 0.4016\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.6082 - acc: 0.8147 - val_loss: 2.6759 - val_acc: 0.4462\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.4298 - acc: 0.8638 - val_loss: 2.7823 - val_acc: 0.4734\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.3069 - acc: 0.9004 - val_loss: 2.2839 - val_acc: 0.5764\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.2340 - acc: 0.9233 - val_loss: 2.7207 - val_acc: 0.5510\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1969 - acc: 0.9351 - val_loss: 2.6801 - val_acc: 0.5594\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1605 - acc: 0.9453 - val_loss: 2.9367 - val_acc: 0.5142\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.1379 - acc: 0.9571 - val_loss: 4.0634 - val_acc: 0.4294\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1334 - acc: 0.9579 - val_loss: 3.3652 - val_acc: 0.5320\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1128 - acc: 0.9628 - val_loss: 2.7195 - val_acc: 0.5946\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0978 - acc: 0.9675 - val_loss: 2.7672 - val_acc: 0.5782\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0944 - acc: 0.9690 - val_loss: 2.9422 - val_acc: 0.5918\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.0925 - acc: 0.9698 - val_loss: 2.8176 - val_acc: 0.5844\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.0783 - acc: 0.9749 - val_loss: 4.8233 - val_acc: 0.3640\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.0757 - acc: 0.9763 - val_loss: 3.1269 - val_acc: 0.5730\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0671 - acc: 0.9761 - val_loss: 3.9627 - val_acc: 0.4748\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0670 - acc: 0.9792 - val_loss: 3.3140 - val_acc: 0.5818\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0645 - acc: 0.9805 - val_loss: 3.0685 - val_acc: 0.5812\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0626 - acc: 0.9799 - val_loss: 5.0816 - val_acc: 0.4052\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0595 - acc: 0.9805 - val_loss: 3.0028 - val_acc: 0.5990\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0535 - acc: 0.9818 - val_loss: 3.3899 - val_acc: 0.5776\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0527 - acc: 0.9819 - val_loss: 8.0976 - val_acc: 0.2696\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0482 - acc: 0.9845 - val_loss: 3.8676 - val_acc: 0.5040\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0454 - acc: 0.9855 - val_loss: 4.5724 - val_acc: 0.4526\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.0525 - acc: 0.9832 - val_loss: 3.8515 - val_acc: 0.5276\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0469 - acc: 0.9850 - val_loss: 6.4896 - val_acc: 0.3282\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.0449 - acc: 0.9852 - val_loss: 3.6162 - val_acc: 0.5674\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0418 - acc: 0.9865 - val_loss: 4.2265 - val_acc: 0.5478\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0439 - acc: 0.9860 - val_loss: 4.5546 - val_acc: 0.4638\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0438 - acc: 0.9855 - val_loss: 3.5607 - val_acc: 0.5786\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0368 - acc: 0.9877 - val_loss: 3.6334 - val_acc: 0.5836\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0369 - acc: 0.9885 - val_loss: 3.4779 - val_acc: 0.6016\n",
      "Epoch 38/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.0396 - acc: 0.9877 - val_loss: 4.0368 - val_acc: 0.5040\n",
      "Epoch 39/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0384 - acc: 0.9883 - val_loss: 3.8870 - val_acc: 0.5680\n",
      "Epoch 40/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0376 - acc: 0.9884 - val_loss: 3.2406 - val_acc: 0.5936\n",
      "Epoch 41/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0398 - acc: 0.9881 - val_loss: 3.5001 - val_acc: 0.5738\n",
      "Epoch 42/50\n",
      "15000/15000 [==============================] - 463s 31ms/step - loss: 0.0335 - acc: 0.9893 - val_loss: 9.2620 - val_acc: 0.2186\n",
      "Epoch 43/50\n",
      "15000/15000 [==============================] - 613s 41ms/step - loss: 0.0311 - acc: 0.9905 - val_loss: 3.7993 - val_acc: 0.5856\n",
      "Epoch 44/50\n",
      "15000/15000 [==============================] - 640s 43ms/step - loss: 0.0329 - acc: 0.9890 - val_loss: 3.4739 - val_acc: 0.5970\n",
      "Epoch 45/50\n",
      "15000/15000 [==============================] - 640s 43ms/step - loss: 0.0288 - acc: 0.9911 - val_loss: 3.5147 - val_acc: 0.5934\n",
      "Epoch 46/50\n",
      "15000/15000 [==============================] - 508s 34ms/step - loss: 0.0304 - acc: 0.9911 - val_loss: 3.6503 - val_acc: 0.5854\n",
      "Epoch 47/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0304 - acc: 0.9903 - val_loss: 4.2601 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0287 - acc: 0.9911 - val_loss: 3.9848 - val_acc: 0.5804\n",
      "Epoch 49/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.0325 - acc: 0.9903 - val_loss: 3.6287 - val_acc: 0.5978\n",
      "Epoch 50/50\n",
      "  100/15000 [..............................] - ETA: 6:47 - loss: 0.0092 - acc: 0.9900"
     ]
    }
   ],
   "source": [
    "modelWithClassifier.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#squeeze/ convert to numpy array so the network can take in the data\n",
    "trainData = np.squeeze(np.array(trainData))\n",
    "testData = np.squeeze(np.array(testData))\n",
    "\n",
    "#train the netwrok\n",
    "modelWithClassifier.fit(trainData, trainDummyLabels, validation_data=(testData, testDummyLabels), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "### For part two, the kernel interupted right before epoch 50 ended, it looks like the best validation accuracy is ~60% which is better than on part one. This is what we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3:\n",
    "### Initializing the network with _____ and training from scratch on the sketches data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertToDummy(labels):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(labels[:,0])\n",
    "    encoded_Y = encoder.transform(labels[:,0])\n",
    "    # convert integers to dummy variables (i.e. one hot encoded)\n",
    "    dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "    return dummy_y\n",
    "\n",
    "trainDummyLabels = convertToDummy(trainLabels)\n",
    "testDummyLabels = convertToDummy(testLabels)\n",
    "\n",
    "trainData = np.squeeze(np.array(trainData))\n",
    "testData = np.squeeze(np.array(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "15000/15000 [==============================] - 468s 31ms/step - loss: 5.6809 - acc: 0.0169 - val_loss: 15.9852 - val_acc: 0.0040\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 4.8691 - acc: 0.0555 - val_loss: 11.5775 - val_acc: 0.0134\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 4.2866 - acc: 0.1264 - val_loss: 16.0536 - val_acc: 0.0040\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 3.8910 - acc: 0.1883 - val_loss: 6.8751 - val_acc: 0.0940\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 3.6472 - acc: 0.2365 - val_loss: 15.5088 - val_acc: 0.0014\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 3.2558 - acc: 0.3096 - val_loss: 9.6328 - val_acc: 0.0138\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 2.9382 - acc: 0.3584 - val_loss: 11.7520 - val_acc: 0.0062\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 2.6400 - acc: 0.4218 - val_loss: 9.5317 - val_acc: 0.0196\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 2.4121 - acc: 0.4664 - val_loss: 12.0314 - val_acc: 0.0126\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 2.2105 - acc: 0.5083 - val_loss: 11.3281 - val_acc: 0.0170\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 2.0321 - acc: 0.5477 - val_loss: 13.2569 - val_acc: 0.0134\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 1.8608 - acc: 0.5817 - val_loss: 8.4889 - val_acc: 0.0656\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 1.7319 - acc: 0.6101 - val_loss: 14.3868 - val_acc: 0.0162\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 1.5781 - acc: 0.6445 - val_loss: 8.9332 - val_acc: 0.0850\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 1.4472 - acc: 0.6745 - val_loss: 11.1898 - val_acc: 0.0452\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 1.3082 - acc: 0.7025 - val_loss: 8.4860 - val_acc: 0.1098\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 1.2900 - acc: 0.7078 - val_loss: 14.5579 - val_acc: 0.0088\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 1.1217 - acc: 0.7484 - val_loss: 9.9827 - val_acc: 0.0730\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 1.0361 - acc: 0.7701 - val_loss: 3.8736 - val_acc: 0.3506\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.8885 - acc: 0.8081 - val_loss: 12.0137 - val_acc: 0.0480\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.8289 - acc: 0.8246 - val_loss: 14.8955 - val_acc: 0.0090\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 0.8270 - acc: 0.8323 - val_loss: 14.1300 - val_acc: 0.0260\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.7691 - acc: 0.8443 - val_loss: 13.3191 - val_acc: 0.0166\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 0.6850 - acc: 0.8639 - val_loss: 13.2490 - val_acc: 0.0256\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.6340 - acc: 0.8829 - val_loss: 11.8570 - val_acc: 0.0744\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.5838 - acc: 0.8974 - val_loss: 3.0838 - val_acc: 0.5138\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.5501 - acc: 0.9068 - val_loss: 13.7053 - val_acc: 0.0392\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.5455 - acc: 0.9101 - val_loss: 8.9543 - val_acc: 0.1776\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.5446 - acc: 0.9095 - val_loss: 15.2252 - val_acc: 0.0098\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.5386 - acc: 0.9108 - val_loss: 3.1490 - val_acc: 0.5010\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.4713 - acc: 0.9167 - val_loss: 3.6548 - val_acc: 0.4920\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.2313 - acc: 0.9283 - val_loss: 15.2477 - val_acc: 0.0148\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 0.1931 - acc: 0.9378 - val_loss: 4.3004 - val_acc: 0.4496\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1636 - acc: 0.9471 - val_loss: 3.6497 - val_acc: 0.5024\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1444 - acc: 0.9529 - val_loss: 14.2035 - val_acc: 0.0308\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1237 - acc: 0.9604 - val_loss: 12.8085 - val_acc: 0.0868\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 462s 31ms/step - loss: 0.1112 - acc: 0.9635 - val_loss: 10.9147 - val_acc: 0.1618\n",
      "Epoch 38/50\n",
      "  800/15000 [>.............................] - ETA: 6:31 - loss: 0.1111 - acc: 0.9562"
     ]
    }
   ],
   "source": [
    "modelFromScratch = ResNet50(include_top=True, weights=None, classes=250)\n",
    "modelFromScratch.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelFromScratch.fit(trainData, trainDummyLabels, validation_data=(testData, testDummyLabels), epochs=50, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "### For part 3 I terminated the kernel because I am sharing the Azure GPU with my group members for the final project and someone else wanted to use it. I figured 37 epochs was enough for this assignment. 2 or 3 times as many would be what I wanted for a well trained network, but was 4-8 hours away. You can see rapid changes in validation accuracy, which is due to the algorithm exploring the space. The best accuracy seen was ~50%, but if continued for longer you might see the network reach >60%, which was what the part 2 network produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
